{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some common over-sampling and under-sampling techniques can be found in [imbalanced-learn](https://imbalanced-learn.readthedocs.io/) library. imbalanced-learn is a python package offering a number of re-sampling techniques commonly used in datasets showing strong between-class imbalance. It is compatible with scikit-learn and is part of scikit-learn-contrib projects.\n",
    "\n",
    "It is easy to add resampling methods on the training of your algorithms through sklearn Pipelines, you can check examples in this tutorial: [Pipeline Object](https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/pipeline/plot_pipeline_classification.html#sphx-glr-auto-examples-pipeline-plot-pipeline-classification-py).\n",
    "**In order for the pipeline to work, you should import `make_pipeline` using**:\n",
    "\n",
    "`from imblearn.pipeline import make_pipeline`\n",
    "\n",
    "and not the `sklearn.pipeline` one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T20:26:35.176411Z",
     "start_time": "2019-06-13T20:26:33.928996Z"
    }
   },
   "source": [
    "Some techniques include: imblearn.over_sampling.RandomOverSampler, imblearn.under_sampling.RandomUnderSampler, and imblearn.SMOTE. For these algorithms there is a nice parameter that allows the user to change the sampling ratio.\n",
    "\n",
    "For example, in SMOTE, to change the ratio you would input a dictionary, and all values must be greater than or equal to the largest class (since SMOTE is an over-sampling technique). The reason I have found SMOTE to be a better fit for model performance in my experience is probably because with RandomOverSampler you are duplicating rows, which means the model can start to memorize the data rather than generalize to new data. SMOTE uses the K-Nearest-Neighbors algorithm to make \"similar\" data points to those under sampled ones.\n",
    "\n",
    "Sometimes it is not good practice to blindly use SMOTE, setting the ratio to it's default (even class balance) because the model may overfit one or more of the minority classes, even though SMOTE is using nearest neighbors to make \"similar\" observations. In a similar way that you tune hyperparameters of a ML model you will tune the hyperparameters of the SMOTE algorithm, such as the ratio and/or knn. Below is a working example of how to properly use SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** It is vital that you do not use resampling methods on the full data set. You MUST use them ONLY on the training set, and then validate on the validation set and test sets to see if your SMOTE model out performed your other model(s). If you do not do this there will be data leakage and you will get a totally irrelevant model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T20:30:26.339942Z",
     "start_time": "2019-06-13T20:30:26.109395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T21:55:11.412803Z",
     "start_time": "2019-06-13T21:55:11.344522Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss, EditedNearestNeighbours,RepeatedEditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if we want to use a keras NN in our Voting Ensemble, we cannot use the native sklearn function. We need to build the ensemble by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T20:30:27.197212Z",
     "start_time": "2019-06-13T20:30:26.863785Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "# plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "DATA_PATH = '../data/'\n",
    "\n",
    "VAL_SPLITS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T20:30:28.001840Z",
     "start_time": "2019-06-13T20:30:27.925640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T21:14:53.380354Z",
     "start_time": "2019-06-13T21:14:53.084314Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot_utils import plot_confusion_matrix\n",
    "from cv_utils import run_cv_f1\n",
    "from cv_utils import plot_cv_roc\n",
    "from cv_utils import plot_cv_roc_prc\n",
    "from cv_utils import print_scores_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T20:33:51.813736Z",
     "start_time": "2019-06-13T20:33:51.706526Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Experimental: Based on LightGMB https://github.com/Microsoft/LightGBM\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, BaggingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T20:33:52.952825Z",
     "start_time": "2019-06-13T20:33:52.891367Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:09:04.177466Z",
     "start_time": "2019-06-13T22:09:04.059481Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn_utils import FeatureSelectorDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the project, we will only work with the training set, that we will split again into train and validation to perform the hyperparameter tuning.\n",
    "\n",
    "We will save the test set for the final part, when we have already tuned our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:38:36.766251Z",
     "start_time": "2019-06-13T22:38:33.210449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>TimeScaled</th>\n",
       "      <th>TimeSin</th>\n",
       "      <th>TimeCos</th>\n",
       "      <th>AmountBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.829392</td>\n",
       "      <td>1.118573</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>1.163686</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.527347</td>\n",
       "      <td>0.173370</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>-0.638939</td>\n",
       "      <td>-0.162923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298908</td>\n",
       "      <td>-0.060301</td>\n",
       "      <td>-0.217935</td>\n",
       "      <td>0.291312</td>\n",
       "      <td>0.120779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460069</td>\n",
       "      <td>-0.480989</td>\n",
       "      <td>0.876727</td>\n",
       "      <td>3.195062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.814527</td>\n",
       "      <td>1.613321</td>\n",
       "      <td>0.654307</td>\n",
       "      <td>0.581821</td>\n",
       "      <td>0.399491</td>\n",
       "      <td>0.730040</td>\n",
       "      <td>0.456233</td>\n",
       "      <td>-2.464347</td>\n",
       "      <td>0.654797</td>\n",
       "      <td>2.248682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329526</td>\n",
       "      <td>-0.307374</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>-2.135657</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266395</td>\n",
       "      <td>-0.204567</td>\n",
       "      <td>-0.978853</td>\n",
       "      <td>3.125269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.105028</td>\n",
       "      <td>-0.700400</td>\n",
       "      <td>-1.338043</td>\n",
       "      <td>-0.596395</td>\n",
       "      <td>-0.395217</td>\n",
       "      <td>-0.755050</td>\n",
       "      <td>-0.276951</td>\n",
       "      <td>-0.291562</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>1.107179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278137</td>\n",
       "      <td>-0.040685</td>\n",
       "      <td>0.789267</td>\n",
       "      <td>-0.066054</td>\n",
       "      <td>-0.069956</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762303</td>\n",
       "      <td>-0.153992</td>\n",
       "      <td>-0.988072</td>\n",
       "      <td>3.421235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.205839</td>\n",
       "      <td>-1.023897</td>\n",
       "      <td>-1.270137</td>\n",
       "      <td>-0.950174</td>\n",
       "      <td>-0.868712</td>\n",
       "      <td>-0.975492</td>\n",
       "      <td>-0.475464</td>\n",
       "      <td>-0.280564</td>\n",
       "      <td>0.503713</td>\n",
       "      <td>0.448173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041177</td>\n",
       "      <td>0.089158</td>\n",
       "      <td>1.105794</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.079881</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879740</td>\n",
       "      <td>-0.998227</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>1.072145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.027090</td>\n",
       "      <td>-0.778666</td>\n",
       "      <td>-1.552755</td>\n",
       "      <td>-0.558679</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>-0.026071</td>\n",
       "      <td>-0.207810</td>\n",
       "      <td>-0.124288</td>\n",
       "      <td>-0.635953</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>-0.157992</td>\n",
       "      <td>-0.606327</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>-0.039868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821649</td>\n",
       "      <td>-0.783558</td>\n",
       "      <td>-0.621319</td>\n",
       "      <td>3.971490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.829392  1.118573  0.926038  1.163686  0.009824  0.527347  0.173370   \n",
       "1 -2.814527  1.613321  0.654307  0.581821  0.399491  0.730040  0.456233   \n",
       "2  2.105028 -0.700400 -1.338043 -0.596395 -0.395217 -0.755050 -0.276951   \n",
       "3  2.205839 -1.023897 -1.270137 -0.950174 -0.868712 -0.975492 -0.475464   \n",
       "4  2.027090 -0.778666 -1.552755 -0.558679  0.020939 -0.026071 -0.207810   \n",
       "\n",
       "         V8        V9       V10  ...       V24       V25       V26       V27  \\\n",
       "0  0.723997 -0.638939 -0.162923  ... -0.298908 -0.060301 -0.217935  0.291312   \n",
       "1 -2.464347  0.654797  2.248682  ... -0.329526 -0.307374 -0.440007 -2.135657   \n",
       "2 -0.291562 -0.965418  1.107179  ... -0.278137 -0.040685  0.789267 -0.066054   \n",
       "3 -0.280564  0.503713  0.448173  ... -0.041177  0.089158  1.105794 -0.066285   \n",
       "4 -0.124288 -0.635953  0.817757  ...  0.033477 -0.157992 -0.606327 -0.003931   \n",
       "\n",
       "        V28  Class  TimeScaled   TimeSin   TimeCos  AmountBC  \n",
       "0  0.120779      0    0.460069 -0.480989  0.876727  3.195062  \n",
       "1  0.011041      0    0.266395 -0.204567 -0.978853  3.125269  \n",
       "2 -0.069956      0    0.762303 -0.153992 -0.988072  3.421235  \n",
       "3 -0.079881      0    0.879740 -0.998227  0.059524  1.072145  \n",
       "4 -0.039868      0    0.821649 -0.783558 -0.621319  3.971490  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH,'df_train.csv'))\n",
    "df.drop(columns= df.columns[0:2],inplace=True)\n",
    "X = df.drop(columns='Class').to_numpy()\n",
    "y = df['Class'].to_numpy()\n",
    "idx_to_feat = dict(enumerate([feat for feat in df.drop(columns='Class').columns ]))\n",
    "feat_to_idx = {feat : idx for idx,feat in idx_to_feat.items()}\n",
    "del(idx_to_feat)\n",
    "cv = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of sampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:36:13.409449Z",
     "start_time": "2019-06-13T22:28:58.156471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.20 +- 0.01\n",
      "train_f1: 0.22 +- 0.01\n",
      "test_average_precision: 0.73 +- 0.08\n",
      "train_average_precision: 0.78 +- 0.02\n",
      "test_roc_auc: 0.98 +- 0.00\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.11 +- 0.00\n",
      "train_precision: 0.13 +- 0.01\n",
      "test_recall: 0.87 +- 0.04\n",
      "train_recall: 0.97 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "over_sampler = SMOTE(random_state=0, n_jobs=-1)\n",
    "clf_ = xgb.sklearn.XGBClassifier(n_jobs=-1,verbosity=0, \n",
    "                                 learning_rate=0.1, \n",
    "                                 random_state=0)\n",
    "clf = make_pipeline(scaler,over_sampler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:10:06.409526Z",
     "start_time": "2019-06-13T22:09:38.818820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.82 +- 0.06\n",
      "train_f1: 1.00 +- 0.00\n",
      "test_average_precision: 0.78 +- 0.07\n",
      "train_average_precision: 1.00 +- 0.00\n",
      "test_roc_auc: 0.92 +- 0.02\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.92 +- 0.03\n",
      "train_precision: 1.00 +- 0.00\n",
      "test_recall: 0.74 +- 0.08\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,scaler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T21:56:36.178657Z",
     "start_time": "2019-06-13T21:55:25.564456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.22 +- 0.01\n",
      "train_f1: 0.30 +- 0.01\n",
      "test_average_precision: 0.68 +- 0.05\n",
      "train_average_precision: 0.94 +- 0.02\n",
      "test_roc_auc: 0.93 +- 0.02\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.13 +- 0.01\n",
      "train_precision: 0.18 +- 0.01\n",
      "test_recall: 0.81 +- 0.04\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "over_sampler = SMOTEENN(random_state=0)\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,scaler,over_sampler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T21:57:40.514466Z",
     "start_time": "2019-06-13T21:56:36.186275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.31 +- 0.01\n",
      "train_f1: 1.00 +- 0.00\n",
      "test_average_precision: 0.69 +- 0.04\n",
      "train_average_precision: 1.00 +- 0.00\n",
      "test_roc_auc: 0.93 +- 0.02\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.19 +- 0.01\n",
      "train_precision: 1.00 +- 0.00\n",
      "test_recall: 0.80 +- 0.06\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "over_sampler = SMOTE(random_state=0, n_jobs=-1)\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,scaler,over_sampler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T21:58:44.873553Z",
     "start_time": "2019-06-13T21:57:40.521615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.30 +- 0.02\n",
      "train_f1: 0.96 +- 0.01\n",
      "test_average_precision: 0.69 +- 0.05\n",
      "train_average_precision: 1.00 +- 0.00\n",
      "test_roc_auc: 0.93 +- 0.03\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.19 +- 0.01\n",
      "train_precision: 0.93 +- 0.02\n",
      "test_recall: 0.79 +- 0.06\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "over_sampler = SMOTETomek(random_state=0)\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,scaler,over_sampler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T21:59:46.949817Z",
     "start_time": "2019-06-13T21:58:44.876792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.30 +- 0.02\n",
      "train_f1: 0.96 +- 0.01\n",
      "test_average_precision: 0.69 +- 0.05\n",
      "train_average_precision: 1.00 +- 0.00\n",
      "test_roc_auc: 0.93 +- 0.03\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.19 +- 0.01\n",
      "train_precision: 0.93 +- 0.02\n",
      "test_recall: 0.79 +- 0.06\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V3','V4','V12','V14','V16','V17']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "over_sampler = NearMiss(random_state=0, n_jobs=-1)\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:00:19.226382Z",
     "start_time": "2019-06-13T21:59:46.953337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.82 +- 0.05\n",
      "train_f1: 0.96 +- 0.01\n",
      "test_average_precision: 0.76 +- 0.07\n",
      "train_average_precision: 0.99 +- 0.01\n",
      "test_roc_auc: 0.92 +- 0.03\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.89 +- 0.04\n",
      "train_precision: 0.93 +- 0.01\n",
      "test_recall: 0.77 +- 0.06\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "over_sampler = EditedNearestNeighbours(random_state=0, n_jobs=-1)\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,scaler,over_sampler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:01:20.249552Z",
     "start_time": "2019-06-13T22:00:19.229976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.81 +- 0.04\n",
      "train_f1: 0.95 +- 0.00\n",
      "test_average_precision: 0.74 +- 0.09\n",
      "train_average_precision: 0.96 +- 0.02\n",
      "test_roc_auc: 0.92 +- 0.03\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.85 +- 0.04\n",
      "train_precision: 0.90 +- 0.01\n",
      "test_recall: 0.78 +- 0.06\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create the samplers\n",
    "enn = EditedNearestNeighbours()\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,scaler,enn,renn,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:02:14.112230Z",
     "start_time": "2019-06-13T22:01:20.253869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.80 +- 0.04\n",
      "train_f1: 0.95 +- 0.01\n",
      "test_average_precision: 0.73 +- 0.10\n",
      "train_average_precision: 0.96 +- 0.02\n",
      "test_roc_auc: 0.92 +- 0.03\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.85 +- 0.02\n",
      "train_precision: 0.90 +- 0.01\n",
      "test_recall: 0.76 +- 0.06\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "# Create the samplers\n",
    "enn = EditedNearestNeighbours()\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,enn,renn,scaler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:13:06.789126Z",
     "start_time": "2019-06-13T22:12:28.601417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.82 +- 0.06\n",
      "train_f1: 1.00 +- 0.00\n",
      "test_average_precision: 0.78 +- 0.07\n",
      "train_average_precision: 1.00 +- 0.00\n",
      "test_roc_auc: 0.92 +- 0.02\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.92 +- 0.03\n",
      "train_precision: 1.00 +- 0.00\n",
      "test_recall: 0.74 +- 0.08\n",
      "train_recall: 1.00 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "list_features = ['V9','V14','V16']\n",
    "feat_select = FeatureSelectorDic(list_features, feat_to_idx)\n",
    "scaler = StandardScaler()\n",
    "over_sampler = EditedNearestNeighbours(random_state=0, n_jobs=-1)\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "clf = make_pipeline(feat_select,scaler,clf_)\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of ensembling classifiers with undersampling\n",
    "A balanced version of bagging algorithms that randomly under-samples each bootstrap sample to\n",
    "balance it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging of logistic regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:22:03.075832Z",
     "start_time": "2019-06-13T22:20:17.468558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.71 +- 0.04\n",
      "train_f1: 0.70 +- 0.01\n",
      "test_average_precision: 0.74 +- 0.05\n",
      "train_average_precision: 0.74 +- 0.01\n",
      "test_roc_auc: 0.96 +- 0.01\n",
      "train_roc_auc: 0.98 +- 0.00\n",
      "test_precision: 0.88 +- 0.04\n",
      "train_precision: 0.86 +- 0.01\n",
      "test_recall: 0.60 +- 0.06\n",
      "train_recall: 0.59 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "base_estimator=LogisticRegression()\n",
    "clf_ = BaggingClassifier(base_estimator=base_estimator,random_state=0,n_jobs=-1)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:20:17.463461Z",
     "start_time": "2019-06-13T22:19:52.072173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.09 +- 0.01\n",
      "train_f1: 0.10 +- 0.02\n",
      "test_average_precision: 0.62 +- 0.04\n",
      "train_average_precision: 0.60 +- 0.07\n",
      "test_roc_auc: 0.97 +- 0.01\n",
      "train_roc_auc: 0.99 +- 0.00\n",
      "test_precision: 0.05 +- 0.00\n",
      "train_precision: 0.05 +- 0.01\n",
      "test_recall: 0.89 +- 0.04\n",
      "train_recall: 0.92 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "base_estimator=LogisticRegression()\n",
    "clf_ = BalancedBaggingClassifier(base_estimator=base_estimator,random_state=0,n_jobs=-1)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging of decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:26:31.368629Z",
     "start_time": "2019-06-13T22:22:03.125632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.82 +- 0.04\n",
      "train_f1: 0.97 +- 0.01\n",
      "test_average_precision: 0.77 +- 0.08\n",
      "train_average_precision: 1.00 +- 0.00\n",
      "test_roc_auc: 0.91 +- 0.03\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.90 +- 0.05\n",
      "train_precision: 0.99 +- 0.01\n",
      "test_recall: 0.76 +- 0.04\n",
      "train_recall: 0.95 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = BaggingClassifier(random_state=0,n_jobs=-1)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:19:52.062760Z",
     "start_time": "2019-06-13T22:19:18.605091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.12 +- 0.02\n",
      "train_f1: 0.13 +- 0.02\n",
      "test_average_precision: 0.52 +- 0.02\n",
      "train_average_precision: 0.57 +- 0.06\n",
      "test_roc_auc: 0.96 +- 0.02\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.06 +- 0.01\n",
      "train_precision: 0.07 +- 0.01\n",
      "test_recall: 0.88 +- 0.02\n",
      "train_recall: 0.99 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = BalancedBaggingClassifier(random_state=0,n_jobs=-1)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:19:18.601336Z",
     "start_time": "2019-06-13T22:18:22.477210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.81 +- 0.05\n",
      "train_f1: 0.97 +- 0.01\n",
      "test_average_precision: 0.76 +- 0.08\n",
      "train_average_precision: 1.00 +- 0.00\n",
      "test_roc_auc: 0.92 +- 0.03\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.89 +- 0.02\n",
      "train_precision: 1.00 +- 0.00\n",
      "test_recall: 0.74 +- 0.07\n",
      "train_recall: 0.94 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = RandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:18:22.465956Z",
     "start_time": "2019-06-13T22:17:35.649006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.11 +- 0.01\n",
      "train_f1: 0.13 +- 0.01\n",
      "test_average_precision: 0.72 +- 0.06\n",
      "train_average_precision: 0.80 +- 0.01\n",
      "test_roc_auc: 0.97 +- 0.01\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.06 +- 0.00\n",
      "train_precision: 0.07 +- 0.01\n",
      "test_recall: 0.88 +- 0.03\n",
      "train_recall: 0.99 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = BalancedRandomForestClassifier(random_state=0,n_jobs=-1)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:28:58.104328Z",
     "start_time": "2019-06-13T22:26:31.376482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.72 +- 0.04\n",
      "train_f1: 0.74 +- 0.00\n",
      "test_average_precision: 0.73 +- 0.08\n",
      "train_average_precision: 0.80 +- 0.01\n",
      "test_roc_auc: 0.97 +- 0.01\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.81 +- 0.03\n",
      "train_precision: 0.82 +- 0.02\n",
      "test_recall: 0.65 +- 0.05\n",
      "train_recall: 0.68 +- 0.02\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = AdaBoostClassifier(random_state=0)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:17:35.630415Z",
     "start_time": "2019-06-13T22:15:59.407459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.07 +- 0.01\n",
      "train_f1: 0.08 +- 0.01\n",
      "test_average_precision: 0.70 +- 0.05\n",
      "train_average_precision: 0.71 +- 0.03\n",
      "test_roc_auc: 0.97 +- 0.01\n",
      "train_roc_auc: 0.99 +- 0.00\n",
      "test_precision: 0.04 +- 0.00\n",
      "train_precision: 0.04 +- 0.01\n",
      "test_recall: 0.89 +- 0.04\n",
      "train_recall: 0.93 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "base_estimator = AdaBoostClassifier(n_estimators=10)\n",
    "clf_ = EasyEnsembleClassifier(base_estimator=base_estimator,random_state=0, n_jobs=-1)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T22:15:59.396968Z",
     "start_time": "2019-06-13T22:14:28.708291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_f1: 0.09 +- 0.00\n",
      "train_f1: 0.09 +- 0.01\n",
      "test_average_precision: 0.69 +- 0.06\n",
      "train_average_precision: 0.70 +- 0.02\n",
      "test_roc_auc: 0.97 +- 0.01\n",
      "train_roc_auc: 1.00 +- 0.00\n",
      "test_precision: 0.05 +- 0.00\n",
      "train_precision: 0.05 +- 0.00\n",
      "test_recall: 0.90 +- 0.02\n",
      "train_recall: 0.94 +- 0.01\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "base_estimator = AdaBoostClassifier(n_estimators=10)\n",
    "clf_ = RUSBoostClassifier(n_estimators=10,\n",
    "                              base_estimator=base_estimator)\n",
    "clf = Pipeline([('scaler',scaler),('clf_',clf_)])\n",
    "\n",
    "scores = cross_validate(clf,X,y,cv=cv,scoring=['f1','average_precision','roc_auc','precision','recall'],n_jobs=-1, return_train_score=True)\n",
    "print_scores_cv(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
