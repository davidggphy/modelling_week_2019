{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Cross Validation (CV) using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first problem we have to attack is to define a metric we want to maximize (or minimize if it is a loss), and we will use it to select the best (or bests) models and hyperparameters. In order to understand the mechanism, we will code the validation loop by hand, and then we will use sklearn functions which do it automatically.\n",
    "\n",
    "Although we are only interested in the metric on the validation set, it is interesting to compare it with the metric on the training set, to check the presence of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:01:15.474853Z",
     "start_time": "2019-06-12T11:01:14.505574Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import sklearn\n",
    "# plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "DATA_PATH = '../data/'\n",
    "\n",
    "VAL_SPLITS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:01:15.547290Z",
     "start_time": "2019-06-12T11:01:15.480008Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot_utils import plot_confusion_matrix\n",
    "from cv_utils import run_cv_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:21:24.883676Z",
     "start_time": "2019-06-12T11:21:24.853751Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the project, we will only work with the training set, that we will split again into train and validation to perform the hyperparameter tuning.\n",
    "\n",
    "We will save the test set for the final part, when we have already tuned our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:01:18.657388Z",
     "start_time": "2019-06-12T11:01:15.556079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>TimeScaled</th>\n",
       "      <th>TimeSin</th>\n",
       "      <th>TimeCos</th>\n",
       "      <th>AmountBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.829392</td>\n",
       "      <td>1.118573</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>1.163686</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.527347</td>\n",
       "      <td>0.173370</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>-0.638939</td>\n",
       "      <td>-0.162923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298908</td>\n",
       "      <td>-0.060301</td>\n",
       "      <td>-0.217935</td>\n",
       "      <td>0.291312</td>\n",
       "      <td>0.120779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460069</td>\n",
       "      <td>-0.480989</td>\n",
       "      <td>0.876727</td>\n",
       "      <td>3.195062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.814527</td>\n",
       "      <td>1.613321</td>\n",
       "      <td>0.654307</td>\n",
       "      <td>0.581821</td>\n",
       "      <td>0.399491</td>\n",
       "      <td>0.730040</td>\n",
       "      <td>0.456233</td>\n",
       "      <td>-2.464347</td>\n",
       "      <td>0.654797</td>\n",
       "      <td>2.248682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329526</td>\n",
       "      <td>-0.307374</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>-2.135657</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266395</td>\n",
       "      <td>-0.204567</td>\n",
       "      <td>-0.978853</td>\n",
       "      <td>3.125269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.105028</td>\n",
       "      <td>-0.700400</td>\n",
       "      <td>-1.338043</td>\n",
       "      <td>-0.596395</td>\n",
       "      <td>-0.395217</td>\n",
       "      <td>-0.755050</td>\n",
       "      <td>-0.276951</td>\n",
       "      <td>-0.291562</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>1.107179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278137</td>\n",
       "      <td>-0.040685</td>\n",
       "      <td>0.789267</td>\n",
       "      <td>-0.066054</td>\n",
       "      <td>-0.069956</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762303</td>\n",
       "      <td>-0.153992</td>\n",
       "      <td>-0.988072</td>\n",
       "      <td>3.421235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.205839</td>\n",
       "      <td>-1.023897</td>\n",
       "      <td>-1.270137</td>\n",
       "      <td>-0.950174</td>\n",
       "      <td>-0.868712</td>\n",
       "      <td>-0.975492</td>\n",
       "      <td>-0.475464</td>\n",
       "      <td>-0.280564</td>\n",
       "      <td>0.503713</td>\n",
       "      <td>0.448173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041177</td>\n",
       "      <td>0.089158</td>\n",
       "      <td>1.105794</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.079881</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879740</td>\n",
       "      <td>-0.998227</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>1.072145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.027090</td>\n",
       "      <td>-0.778666</td>\n",
       "      <td>-1.552755</td>\n",
       "      <td>-0.558679</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>-0.026071</td>\n",
       "      <td>-0.207810</td>\n",
       "      <td>-0.124288</td>\n",
       "      <td>-0.635953</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>-0.157992</td>\n",
       "      <td>-0.606327</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>-0.039868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821649</td>\n",
       "      <td>-0.783558</td>\n",
       "      <td>-0.621319</td>\n",
       "      <td>3.971490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.829392  1.118573  0.926038  1.163686  0.009824  0.527347  0.173370   \n",
       "1 -2.814527  1.613321  0.654307  0.581821  0.399491  0.730040  0.456233   \n",
       "2  2.105028 -0.700400 -1.338043 -0.596395 -0.395217 -0.755050 -0.276951   \n",
       "3  2.205839 -1.023897 -1.270137 -0.950174 -0.868712 -0.975492 -0.475464   \n",
       "4  2.027090 -0.778666 -1.552755 -0.558679  0.020939 -0.026071 -0.207810   \n",
       "\n",
       "         V8        V9       V10  ...       V24       V25       V26       V27  \\\n",
       "0  0.723997 -0.638939 -0.162923  ... -0.298908 -0.060301 -0.217935  0.291312   \n",
       "1 -2.464347  0.654797  2.248682  ... -0.329526 -0.307374 -0.440007 -2.135657   \n",
       "2 -0.291562 -0.965418  1.107179  ... -0.278137 -0.040685  0.789267 -0.066054   \n",
       "3 -0.280564  0.503713  0.448173  ... -0.041177  0.089158  1.105794 -0.066285   \n",
       "4 -0.124288 -0.635953  0.817757  ...  0.033477 -0.157992 -0.606327 -0.003931   \n",
       "\n",
       "        V28  Class  TimeScaled   TimeSin   TimeCos  AmountBC  \n",
       "0  0.120779      0    0.460069 -0.480989  0.876727  3.195062  \n",
       "1  0.011041      0    0.266395 -0.204567 -0.978853  3.125269  \n",
       "2 -0.069956      0    0.762303 -0.153992 -0.988072  3.421235  \n",
       "3 -0.079881      0    0.879740 -0.998227  0.059524  1.072145  \n",
       "4 -0.039868      0    0.821649 -0.783558 -0.621319  3.971490  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH,'df_train.csv'))\n",
    "df.drop(columns= df.columns[0:2],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Manual cross validation (Exercise, built the CV loop)\n",
    "\n",
    "We can do it manually, although it is better to define a function to help us iterate the CV over different algorithms and hyperparameters. It is more convenient to create a function, which is `run_cv_f1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is a typical CV loop, built from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T10:37:38.812060Z",
     "start_time": "2019-06-12T10:36:33.734878Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-fold / 4 completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "Metric value (Train): 0.67 Â± 0.01\n",
      "Metric value(Val): 0.69 Â± 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "clf = LogisticRegression(solver='sag',random_state=0,n_jobs=-1)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "# We create two eampty lists to save the metrics at each fold for train and validation. \n",
    "metrics = []\n",
    "metrics_train = []\n",
    "# Loop over the different validation folds\n",
    "for i,(idx_t, idx_v) in enumerate(cv.split(X,y)):\n",
    "    X_train = X[idx_t]\n",
    "    y_train = y[idx_t]\n",
    "    X_val = X[idx_v]\n",
    "    y_val = y[idx_v]\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_val)\n",
    "    metric = f1_score(y_val,y_pred)\n",
    "    metrics.append(metric)\n",
    "    \n",
    "    y_t_pred = clf.predict(X_train)\n",
    "    metric_train = f1_score(y_train,y_t_pred)\n",
    "    metrics_train.append(metric_train)\n",
    "    \n",
    "    print('{}-fold / {} completed!'.format(i+1,VAL_SPLITS))\n",
    "    \n",
    "metric_mean = np.mean(metrics)\n",
    "metric_std = np.std(metrics, ddof=1)\n",
    "metric_t_mean = np.mean(metrics_train)\n",
    "metric_t_std = np.std(metrics_train, ddof=1)\n",
    "print('Metric value (Train): {:.2f} Â± {:.2f}'.format(metric_t_mean,metric_t_std))\n",
    "print('Metric value(Val): {:.2f} Â± {:.2f}'.format(metric_mean,metric_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The same code can be casted in the form of a function, `run_cv_f1`, which can be found in `cv_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:01:30.197113Z",
     "start_time": "2019-06-12T11:01:22.335568Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.61 Â± 0.01\n",
      "F1 value (Val): 0.63 Â± 0.06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6105263157894737,\n",
       "  0.5869565217391305,\n",
       "  0.608695652173913,\n",
       "  0.7200000000000001],\n",
       " [0.6099815157116452,\n",
       "  0.613970588235294,\n",
       "  0.608534322820037,\n",
       "  0.5906542056074766])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "clf = LogisticRegression(solver='sag',random_state=0,n_jobs=-1)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V12','AmountBC','V16','V9']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:03:54.030797Z",
     "start_time": "2019-06-12T11:01:40.414399Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 1.00 Â± 0.00\n",
      "F1 value (Val): 0.77 Â± 0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.7747747747747747,\n",
       "  0.6981132075471699,\n",
       "  0.7884615384615384,\n",
       "  0.8288288288288289],\n",
       " [1.0, 1.0, 0.9985358711566619, 1.0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "clf = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=0)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V12','AmountBC','V16','V9']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:03:54.160423Z",
     "start_time": "2019-06-12T11:03:54.034469Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V12 45.168946351201825\n",
      "AmountBC 8.546067680924292\n",
      "V16 27.534791680607483\n",
      "V9 18.750194287266396\n"
     ]
    }
   ],
   "source": [
    "for name, value in zip(df_.drop(columns='Class').columns,100*clf.feature_importances_):\n",
    "    print(name,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:04:35.737689Z",
     "start_time": "2019-06-12T11:03:54.166067Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.68 Â± 0.03\n",
      "F1 value (Val): 0.66 Â± 0.08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.6732673267326732,\n",
       "  0.5625000000000001,\n",
       "  0.6470588235294117,\n",
       "  0.7547169811320754],\n",
       " [0.7177700348432056,\n",
       "  0.6884681583476764,\n",
       "  0.6598290598290599,\n",
       "  0.6514886164623468])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "clf = AdaBoostClassifier(random_state=0)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V12','AmountBC','V16','V9']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:04:44.352059Z",
     "start_time": "2019-06-12T11:04:44.337361Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V12 44.0\n",
      "AmountBC 14.000000000000002\n",
      "V16 18.0\n",
      "V9 24.0\n"
     ]
    }
   ],
   "source": [
    "for name, val in zip(df_.drop(columns='Class').columns,100*clf.feature_importances_):\n",
    "    print(name,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:06:23.373903Z",
     "start_time": "2019-06-12T11:06:23.366818Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:13:01.549497Z",
     "start_time": "2019-06-12T11:12:58.010064Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.08 Â± 0.01\n",
      "F1 value (Val): 0.08 Â± 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = LogisticRegression(solver='lbfgs',random_state=0,class_weight='balanced',n_jobs=-1)\n",
    "clf = Pipeline([('scaler', scaler), ('LogReg', clf_)])\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:12:57.596160Z",
     "start_time": "2019-06-12T11:12:53.327405Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.08 Â± 0.01\n",
      "F1 value (Val): 0.08 Â± 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs',random_state=0,class_weight='balanced',n_jobs=-1)\n",
    "\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:12:50.680537Z",
     "start_time": "2019-06-12T11:12:46.654751Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.67 Â± 0.01\n",
      "F1 value (Val): 0.66 Â± 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = LogisticRegression(solver='lbfgs',random_state=0,class_weight=None,n_jobs=-1)\n",
    "clf = Pipeline([('scaler', scaler), ('LogReg', clf_)])\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:12:19.263458Z",
     "start_time": "2019-06-12T11:12:16.449884Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.61 Â± 0.01\n",
      "F1 value (Val): 0.63 Â± 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs',random_state=0,class_weight=None,n_jobs=-1)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V12','AmountBC','V16','V9']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:15:15.657030Z",
     "start_time": "2019-06-12T11:13:48.793431Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.87 Â± 0.01\n",
      "F1 value (Val): 0.81 Â± 0.07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "clf = Pipeline([('scaler', scaler), ('LogReg', clf_)])\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:16:39.592084Z",
     "start_time": "2019-06-12T11:15:15.662704Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.87 Â± 0.01\n",
      "F1 value (Val): 0.80 Â± 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:18:49.322765Z",
     "start_time": "2019-06-12T11:16:39.595350Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 1.00 Â± 0.00\n",
      "F1 value (Val): 0.80 Â± 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,n_jobs=-1,random_state=0)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:19:50.411896Z",
     "start_time": "2019-06-12T11:18:49.326392Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.74 Â± 0.01\n",
      "F1 value (Val): 0.73 Â± 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:20:11.106053Z",
     "start_time": "2019-06-12T11:19:50.414734Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 1.00 Â± 0.00\n",
      "F1 value (Val): 0.81 Â± 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:21:01.425280Z",
     "start_time": "2019-06-12T11:20:11.108951Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 1.00 Â± 0.00\n",
      "F1 value (Val): 0.82 Â± 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:21:58.066123Z",
     "start_time": "2019-06-12T11:21:30.230313Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.81 Â± 0.01\n",
      "F1 value (Val): 0.78 Â± 0.05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                 hidden_layer_sizes=(16,8,2), random_state=0)\n",
    "clf = Pipeline([('scaler', scaler), ('clf_', clf_)])\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df[['Class','V4','V14','V16','V17','V18','TimeSin','AmountBC']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:24:04.676114Z",
     "start_time": "2019-06-12T11:21:58.069557Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fold / 4 completed!\n",
      "2-fold / 4 completed!\n",
      "3-fold / 4 completed!\n",
      "4-fold / 4 completed!\n",
      "F1 value (Train): 0.97 Â± 0.01\n",
      "F1 value (Val): 0.79 Â± 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "clf_ = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                 hidden_layer_sizes=(16,8,2), random_state=0)\n",
    "clf = Pipeline([('scaler', scaler), ('clf_', clf_)])\n",
    "\n",
    "# In case we want to select a subset of features\n",
    "df_ = df\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "\n",
    "run_cv_f1(clf,cv,X,y)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn function for CV (Preferred)\n",
    "\n",
    "Even if it is easy to build the CV loop, and we can change the metric and the outputs in a personalized way, using a `for` loop makes the CV step non parallelizable (we could use the library `multiprocessing`) to solve this, but `sklearn` has implemented such an utility.\n",
    "\n",
    "These utilities can be found in sklearn's [webpage](https://scikit-learn.org/stable/modules/classes.html#model-validation). Some of them are:\n",
    "* [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) : Returning the validation score for some given metric.\n",
    "* [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) : Evaluate metric(s) by cross-validation and also record fit/score times. It can also returns the train metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:44:38.395779Z",
     "start_time": "2019-06-12T11:44:38.391689Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:45:51.076818Z",
     "start_time": "2019-06-12T11:45:37.709506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 value (Val): 0.82 Â± 0.06\n"
     ]
    }
   ],
   "source": [
    "val_split = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "clf = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "df_ = df[['Class','V9','V14','V16']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "metrics = cross_val_score(clf,X,y,cv=val_split,scoring='f1',n_jobs=-1)\n",
    "print('F1 value (Val): {:.2f} Â± {:.2f}'.format(\n",
    "                np.mean(metrics),\n",
    "                np.std(metrics, ddof=1)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:49:23.576605Z",
     "start_time": "2019-06-12T11:49:11.318059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 value (Train): 1.00 Â± 0.00\n",
      "F1 value (Val): 0.82 Â± 0.06\n"
     ]
    }
   ],
   "source": [
    "val_split = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "clf = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "df_ = df[['Class','V9','V14','V16']]\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "scores = cross_validate(clf,X,y,cv=val_split,scoring='f1',n_jobs=-1, return_train_score=True)\n",
    "print('F1 value (Train): {:.2f} Â± {:.2f}'.format(\n",
    "                np.mean(scores['train_score']),\n",
    "                np.std(scores['train_score'], ddof=1)\n",
    "            ))\n",
    "print('F1 value (Val): {:.2f} Â± {:.2f}'.format(\n",
    "                np.mean(scores['test_score']),\n",
    "                np.std(scores['test_score'], ddof=1)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T11:51:17.403632Z",
     "start_time": "2019-06-12T11:50:05.417820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 value (Val): 0.82 Â± 0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "clf_ = ExtraTreesClassifier(n_estimators=50,n_jobs=-1,random_state=0)\n",
    "cv = StratifiedShuffleSplit(n_splits=2,test_size=0.2,random_state=0)\n",
    "# Calibrated with isotonic calibration\n",
    "clf = CalibratedClassifierCV(clf_, cv=cv, method='isotonic')\n",
    "df_ = df\n",
    "X = df_.drop(columns='Class').to_numpy()\n",
    "y = df_['Class'].to_numpy()\n",
    "metrics = cross_val_score(clf,X,y,cv=val_split,scoring='f1',n_jobs=-1)\n",
    "print('F1 value (Val): {:.2f} Â± {:.2f}'.format(\n",
    "                np.mean(metrics),\n",
    "                np.std(metrics, ddof=1)\n",
    "            ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
