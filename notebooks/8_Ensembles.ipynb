{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles of classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if we want to use a keras NN in our Voting Ensemble, we cannot use the native sklearn function. We need to build the ensemble by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:17:50.934344Z",
     "start_time": "2019-06-13T16:17:50.872704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:52:41.032578Z",
     "start_time": "2019-06-14T09:52:39.157232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "import sklearn\n",
    "# plt.style.use('fivethirtyeight')\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "DATA_PATH = '../data/'\n",
    "\n",
    "VAL_SPLITS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:52:48.558526Z",
     "start_time": "2019-06-14T09:52:41.035587Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danky/anaconda3/envs/fraud_credit/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:52:48.636749Z",
     "start_time": "2019-06-14T09:52:48.565524Z"
    }
   },
   "outputs": [],
   "source": [
    "from plot_utils import plot_confusion_matrix\n",
    "from cv_utils import run_cv_f1\n",
    "from cv_utils import plot_cv_roc\n",
    "from cv_utils import plot_cv_roc_prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:52:49.100654Z",
     "start_time": "2019-06-14T09:52:48.638938Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Experimental: Based on LightGMB https://github.com/Microsoft/LightGBM\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "# Pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "from sklearn_utils import FeatureSelectorDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the project, we will only work with the training set, that we will split again into train and validation to perform the hyperparameter tuning.\n",
    "\n",
    "We will save the test set for the final part, when we have already tuned our hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:52:59.539811Z",
     "start_time": "2019-06-14T09:52:56.671441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>TimeScaled</th>\n",
       "      <th>TimeSin</th>\n",
       "      <th>TimeCos</th>\n",
       "      <th>AmountBC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.829392</td>\n",
       "      <td>1.118573</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>1.163686</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.527347</td>\n",
       "      <td>0.173370</td>\n",
       "      <td>0.723997</td>\n",
       "      <td>-0.638939</td>\n",
       "      <td>-0.162923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298908</td>\n",
       "      <td>-0.060301</td>\n",
       "      <td>-0.217935</td>\n",
       "      <td>0.291312</td>\n",
       "      <td>0.120779</td>\n",
       "      <td>0</td>\n",
       "      <td>0.460069</td>\n",
       "      <td>-0.480989</td>\n",
       "      <td>0.876727</td>\n",
       "      <td>3.195062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.814527</td>\n",
       "      <td>1.613321</td>\n",
       "      <td>0.654307</td>\n",
       "      <td>0.581821</td>\n",
       "      <td>0.399491</td>\n",
       "      <td>0.730040</td>\n",
       "      <td>0.456233</td>\n",
       "      <td>-2.464347</td>\n",
       "      <td>0.654797</td>\n",
       "      <td>2.248682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.329526</td>\n",
       "      <td>-0.307374</td>\n",
       "      <td>-0.440007</td>\n",
       "      <td>-2.135657</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266395</td>\n",
       "      <td>-0.204567</td>\n",
       "      <td>-0.978853</td>\n",
       "      <td>3.125269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.105028</td>\n",
       "      <td>-0.700400</td>\n",
       "      <td>-1.338043</td>\n",
       "      <td>-0.596395</td>\n",
       "      <td>-0.395217</td>\n",
       "      <td>-0.755050</td>\n",
       "      <td>-0.276951</td>\n",
       "      <td>-0.291562</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>1.107179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278137</td>\n",
       "      <td>-0.040685</td>\n",
       "      <td>0.789267</td>\n",
       "      <td>-0.066054</td>\n",
       "      <td>-0.069956</td>\n",
       "      <td>0</td>\n",
       "      <td>0.762303</td>\n",
       "      <td>-0.153992</td>\n",
       "      <td>-0.988072</td>\n",
       "      <td>3.421235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.205839</td>\n",
       "      <td>-1.023897</td>\n",
       "      <td>-1.270137</td>\n",
       "      <td>-0.950174</td>\n",
       "      <td>-0.868712</td>\n",
       "      <td>-0.975492</td>\n",
       "      <td>-0.475464</td>\n",
       "      <td>-0.280564</td>\n",
       "      <td>0.503713</td>\n",
       "      <td>0.448173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041177</td>\n",
       "      <td>0.089158</td>\n",
       "      <td>1.105794</td>\n",
       "      <td>-0.066285</td>\n",
       "      <td>-0.079881</td>\n",
       "      <td>0</td>\n",
       "      <td>0.879740</td>\n",
       "      <td>-0.998227</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>1.072145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.027090</td>\n",
       "      <td>-0.778666</td>\n",
       "      <td>-1.552755</td>\n",
       "      <td>-0.558679</td>\n",
       "      <td>0.020939</td>\n",
       "      <td>-0.026071</td>\n",
       "      <td>-0.207810</td>\n",
       "      <td>-0.124288</td>\n",
       "      <td>-0.635953</td>\n",
       "      <td>0.817757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033477</td>\n",
       "      <td>-0.157992</td>\n",
       "      <td>-0.606327</td>\n",
       "      <td>-0.003931</td>\n",
       "      <td>-0.039868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.821649</td>\n",
       "      <td>-0.783558</td>\n",
       "      <td>-0.621319</td>\n",
       "      <td>3.971490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.829392  1.118573  0.926038  1.163686  0.009824  0.527347  0.173370   \n",
       "1 -2.814527  1.613321  0.654307  0.581821  0.399491  0.730040  0.456233   \n",
       "2  2.105028 -0.700400 -1.338043 -0.596395 -0.395217 -0.755050 -0.276951   \n",
       "3  2.205839 -1.023897 -1.270137 -0.950174 -0.868712 -0.975492 -0.475464   \n",
       "4  2.027090 -0.778666 -1.552755 -0.558679  0.020939 -0.026071 -0.207810   \n",
       "\n",
       "         V8        V9       V10  ...       V24       V25       V26       V27  \\\n",
       "0  0.723997 -0.638939 -0.162923  ... -0.298908 -0.060301 -0.217935  0.291312   \n",
       "1 -2.464347  0.654797  2.248682  ... -0.329526 -0.307374 -0.440007 -2.135657   \n",
       "2 -0.291562 -0.965418  1.107179  ... -0.278137 -0.040685  0.789267 -0.066054   \n",
       "3 -0.280564  0.503713  0.448173  ... -0.041177  0.089158  1.105794 -0.066285   \n",
       "4 -0.124288 -0.635953  0.817757  ...  0.033477 -0.157992 -0.606327 -0.003931   \n",
       "\n",
       "        V28  Class  TimeScaled   TimeSin   TimeCos  AmountBC  \n",
       "0  0.120779      0    0.460069 -0.480989  0.876727  3.195062  \n",
       "1  0.011041      0    0.266395 -0.204567 -0.978853  3.125269  \n",
       "2 -0.069956      0    0.762303 -0.153992 -0.988072  3.421235  \n",
       "3 -0.079881      0    0.879740 -0.998227  0.059524  1.072145  \n",
       "4 -0.039868      0    0.821649 -0.783558 -0.621319  3.971490  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_PATH,'df_train.csv'))\n",
    "df.drop(columns= df.columns[0:2],inplace=True)\n",
    "\n",
    "idx_to_feat = dict(enumerate([feat for feat in df.columns if feat is not 'Class']))\n",
    "feat_to_idx = {feat : idx for idx,feat in idx_to_feat.items()}\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=VAL_SPLITS,test_size=0.15,random_state=0)\n",
    "\n",
    "X = df.drop(columns='Class').to_numpy()\n",
    "y = df['Class'].to_numpy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble by hand (Hard voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:59:30.977285Z",
     "start_time": "2019-06-14T09:59:30.966608Z"
    }
   },
   "outputs": [],
   "source": [
    "def hard_vote_predict(estimators, X, weights=None):\n",
    "    \"\"\"\n",
    "    Combine a dictionary of estimators to create a hard voting ensemble.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimators : dict\n",
    "        Dictionary with name (str): model entries with predict method.\n",
    "        If the method predict returns probabilities, then the name should\n",
    "        end with 'prob'.\n",
    "    X : np.array\n",
    "        Input.\n",
    "    weights : list, tuple or np.array, default=None\n",
    "        List of weights for each estimator. If None, then it is uniform.\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(estimators))\n",
    "    else:\n",
    "        assert len(weights) == len(\n",
    "            estimators), 'Number of estimators should be the same as number of weights'\n",
    "        weights = np.array(weights)\n",
    "    weights = weights.reshape((-1, 1))\n",
    "    y_preds = []\n",
    "    for name, clf in estimators.items():\n",
    "        y_pred = clf.predict(X)\n",
    "        if name.endswith('prob'):\n",
    "            y_pred = (1 * (y_pred > 0.5)).reshape((-1))\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    y_preds = np.array(y_preds)\n",
    "    y_final = 1 * (np.mean(weights * y_preds, axis=0) > 0.5)\n",
    "    return y_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T09:53:44.535768Z",
     "start_time": "2019-06-14T09:53:44.529494Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "def create_clf(input_dim):\n",
    "    clf1 = Sequential([\n",
    "        Dense(8, input_shape=(input_dim,)),\n",
    "        LeakyReLU(),\n",
    "        Dense(4),\n",
    "        LeakyReLU(),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ], name='clf')\n",
    "    return clf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:18:43.711997Z",
     "start_time": "2019-06-13T16:18:43.557891Z"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = X.shape[1]\n",
    "\n",
    "clf1 = create_clf(INPUT_DIM)\n",
    "clf1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy')\n",
    "# clf2 = RandomForestClassifier(n_estimators=100,\n",
    "#                               max_depth=6,\n",
    "#                               random_state=0,n_jobs=-1, max_features=6)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "clf3 = xgb.sklearn.XGBClassifier(n_jobs=-1,max_depth=5, random_state=0)\n",
    "# clf3 = LogisticRegression(n_jobs=-1)\n",
    "sklearn_clfs = [clf2,clf3]\n",
    "clfs = [clf1]+sklearn_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-13T16:23:35.514942Z",
     "start_time": "2019-06-13T16:18:45.457242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 has ended!\n",
      "Fold 2 has ended!\n",
      "Fold 3 has ended!\n",
      "Fold 4 has ended!\n",
      "Metric value validation(va): 0.82 +- 0.05\n",
      "Metric value train: 0.88 +- 0.00\n"
     ]
    }
   ],
   "source": [
    "metrics = []\n",
    "accuracy = []\n",
    "precision = []\n",
    "metrics_train = []\n",
    "accuracy_train = []\n",
    "precision_train = []\n",
    "\n",
    "for i, (idx_t, idx_v) in enumerate(cv.split(X,y)):\n",
    "    X_train = X[idx_t]\n",
    "    y_train = y[idx_t]\n",
    "    X_val = X[idx_v]\n",
    "    y_val = y[idx_v]\n",
    "    #Devuelve cuatro vectrores de dos elementos, el primero con los indices de train y el segundo con \n",
    "    #los de validacion \n",
    "    \n",
    "    clf1.fit(X_train,y_train,batch_size=512,epochs=50,verbose=0)\n",
    "    for clf_ in sklearn_clfs:\n",
    "        clf_.fit(X_train,y_train)\n",
    "    \n",
    "    estimators = dict(zip(['nn_prob','rf','knn'],clfs))\n",
    "    y_pred = hard_vote_predict(estimators,X_val)\n",
    "\n",
    "\n",
    "    acc_va = accuracy_score(y_val, y_pred)\n",
    "    pre_va = precision_score(y_val, y_pred)\n",
    "#     error_va = mean_squared_error(y_val, y_pred)\n",
    "    f1_va = f1_score(y_val, y_pred)\n",
    "    #print('Recall:', acc)\n",
    "    #print('Precision:', pre)\n",
    "    #print('Error cuadratico medio:', error)\n",
    "    \n",
    "    y_pred_train = hard_vote_predict(estimators,X_train)\n",
    "\n",
    "    acc_train = accuracy_score(y_train, y_pred_train)\n",
    "    pre_train = precision_score(y_train, y_pred_train)\n",
    "#     error_train = mean_squared_error(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    \n",
    "    metrics.append(f1_va)\n",
    "    accuracy.append(acc_va)\n",
    "    precision.append(pre_va)\n",
    "    \n",
    "    metrics_train.append(f1_train)\n",
    "    accuracy_train.append(acc_train)\n",
    "    precision_train.append(pre_train)\n",
    "    print('Fold {} has ended!'.format(i+1))\n",
    "metric_mean = np.mean(metrics)\n",
    "metric_std = np.std(metrics, ddof = 1)\n",
    "print('Metric value validation(va): {:.2f} +- {:.2f}'.format(metric_mean,metric_std))\n",
    "#print('Mean validation: recall {:.4f} precision {:.4f}'.format(np.mean(accuracy), np.mean(precision)))\n",
    "\n",
    "\n",
    "metric_train_mean = np.mean(metrics_train)\n",
    "metric_train_std = np.std(metrics_train, ddof = 1)\n",
    "print('Metric value train: {:.2f} +- {:.2f}'.format(metric_train_mean,metric_train_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
